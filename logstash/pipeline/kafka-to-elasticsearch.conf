# kafka-to-elasticsearch.conf
input {
  kafka {
    bootstrap_servers => "${KAFKA_BOOTSTRAP_SERVERS}"
    topics => ["TRANSACTIONS_PER_USER", "TRANSACTIONS_PER_MINUTE", "TRANSACTION_SUMMARY"]
    codec => "json"
    decorate_events => basic
    consumer_threads => 3
    # ConfiguraciÃ³n de autenticaciÃ³n SASL/PLAIN
    sasl_mechanism => "PLAIN"
    security_protocol => "SASL_PLAINTEXT"  # Cambia a "SASL_SSL" si es necesario
    sasl_jaas_config => "org.apache.kafka.common.security.plain.PlainLoginModule required username='${KAFKA_USERNAME}' password='${KAFKA_PASSWORD}';"
    # Opciones adicionales
    group_id => "logstash-consumer-group"  # Define un grupo de consumidores para Logstash
    auto_offset_reset => "earliest"  # Comienza desde el principio si no hay offsets almacenados
  }
}

filter {
    if [@metadata][kafka][topic] == "TRANSACTIONS_PER_USER" {
      mutate { add_field => { "[@metadata][target_index]" => "transactions_per_user_index" } }
    } else if [@metadata][kafka][topic] == "TRANSACTIONS_PER_MINUTE" {
      mutate { add_field => { "[@metadata][target_index]" => "transactions_per_minute_index" } }
    } else if [@metadata][kafka][topic] == "TRANSACTION_SUMMARY" {
      mutate { add_field => { "[@metadata][target_index]" => "transaction_summary_index" } }
    }
}

output {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      user => "${ELASTIC_USERNAME}"
      password => "${ELASTIC_PASSWORD}"
      index => "%{[@metadata][target_index]}"
      document_id => "%{[@metadata][kafka][key]}"
      action => "index"
    }
  stdout { codec => json_lines }
}